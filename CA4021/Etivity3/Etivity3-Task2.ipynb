{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<hr style=\\\"border:2px solid gray\\\"> </hr>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<hr style=\\\"border:2px solid gray\\\"> </hr>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:50:14.794949Z",
     "start_time": "2024-10-20T08:50:14.769728Z"
    }
   },
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:50:16.449587Z",
     "start_time": "2024-10-20T08:50:16.406664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NaiveBayesSpamFilter :\n",
    "    \"\"\"\n",
    "        Naive Bayes SPAM filter\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stop_words, previous_ham, previous_spam) :\n",
    "        \"\"\"Class Init\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        :param stop_words: List of stop words\n",
    "        :param previous_spam: previous spam\n",
    "        :param previous_ham: previous ham \n",
    "        \"\"\"\n",
    "\n",
    "        self._stop_words = stop_words\n",
    "        self.previous_spam = previous_spam\n",
    "        self.previous_ham = previous_ham\n",
    "        self.training_set = self.previous_ham + self.previous_spam\n",
    "        self.P_S = len(self.previous_spam) / len(self.training_set)\n",
    "        self.P_H  = 1 - self.P_S\n",
    "        self._ham_bag_of_words = None\n",
    "        self._spam_bag_of_words = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def _log_calculator(x):\n",
    "        \"\"\"Calculate the log of a value - very crude , we don't care for the POC \n",
    "        \"\"\"\n",
    "            \n",
    "        n = 1000.0\n",
    "        return n * ((x ** (1/n)) - 1)\n",
    "    \n",
    "    def build_training_set_dictionary(self):\n",
    "        \"\"\"Builds a bag of words dictionary for the training set\n",
    "        \"\"\"\n",
    "        self._ham_bag_of_words = self.StatisticsScenario(self.previous_ham, self._stop_words, dict())\n",
    "        self._ham_bag_of_words.fit()\n",
    "        \n",
    "        print(\"Global bag of words for ham -----------------\")\n",
    "        print(self._ham_bag_of_words.bag_of_words.keys())\n",
    "        print(self._ham_bag_of_words.bag_of_words.values())\n",
    "        print(\"\")\n",
    "         \n",
    "        self._spam_bag_of_words = self.StatisticsScenario(self.previous_spam, self._stop_words, dict())\n",
    "        self._spam_bag_of_words.fit()\n",
    "        \n",
    "        print(\"Global bag of words for spam ---------------\")\n",
    "        print(self._spam_bag_of_words.bag_of_words.keys())\n",
    "        print(self._spam_bag_of_words.bag_of_words.values())\n",
    "        print(\"\")\n",
    "        \n",
    "    def predict(self, sample_data):\n",
    "        \"\"\"Classify the input and see if they are indeed spam or ham.\n",
    "        \n",
    "           Using the log of PS / PH + sum log of P(x | S) / P(x | H)\n",
    "        \"\"\"\n",
    "        \n",
    "        for label, subjects  in sample_data.items() :\n",
    "            print(label + \": %s\" % subjects)\n",
    "            \n",
    "            for subject in subjects :\n",
    "                new_spam_bag = self._spam_bag_of_words.build_bag_from_input(subjects, subject)\n",
    "                new_ham_bag = self._ham_bag_of_words.build_bag_from_input(subjects, subject)\n",
    "            \n",
    "                spam_probability = self._log_calculator(spamFilter.P_S) + new_spam_bag.calculate_P_Sum()\n",
    "                ham_probability = self._log_calculator(spamFilter.P_H) + new_ham_bag.calculate_P_Sum()\n",
    "                \n",
    "                print(f\"spam P: {spam_probability} ham P: {ham_probability}\")\n",
    "                print(\"spam\" if spam_probability > ham_probability else \"ham\")\n",
    "        \n",
    "    class StatisticsScenario:\n",
    "\n",
    "        def __init__(self, training_data, stop_words, bag_of_words):\n",
    "            self.training_data = training_data\n",
    "            self._stop_words = stop_words\n",
    "            self.bag_of_words = bag_of_words  \n",
    "    \n",
    "        def build_bag_from_input(self, training_data, sample_subject):\n",
    "            \"\"\"Build a stats object from the \n",
    "            \"\"\"\n",
    "    \n",
    "            sample_data_bag = dict()\n",
    "            for word in self._remove_stop_words(self._clear_text(sample_subject), self._stop_words).split() :\n",
    "                if word in self.bag_of_words:\n",
    "                    sample_data_bag[word] = self.bag_of_words[word]\n",
    "                        \n",
    "            return type(self)(training_data, self._stop_words, sample_data_bag)\n",
    "        \n",
    "        def fit(self):\n",
    "            \"\"\"Update the count and probability of each word\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            self._update_word_count()\n",
    "            self._update_word_probability()\n",
    "            \n",
    "        def calculate_P_Sum(self):\n",
    "            \"\"\"Calculate the probability of all the words with a sum of all the log values \n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            return sum([self._log_calculator(stat.probability) for stat in self.bag_of_words.values()])\n",
    "        \n",
    "        @staticmethod\n",
    "        def _log_calculator(x):\n",
    "            \"\"\"Calculate the log of a value - very crude , we don't care for the POC \n",
    "            \"\"\"\n",
    "            \n",
    "            n = 1000.0\n",
    "            return n * ((x ** (1/n)) - 1)\n",
    "                    \n",
    "        @staticmethod\n",
    "        def _clear_text(text) :\n",
    "            \"\"\" Remove special characters from the input text and lower the casing of the word \n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            :param text: input word \n",
    "            \n",
    "            :return: a stripped down version of the input word\n",
    "            \"\"\"\n",
    "            \n",
    "            return text.lower().rstrip().strip()\n",
    "    \n",
    "        @staticmethod\n",
    "        def _remove_stop_words(text, stop_words):\n",
    "            \"\"\"Return the number of runs\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            :param text: input text\n",
    "            :param stop_words: words to ignore\n",
    "            \n",
    "            :return: a text without stop words\n",
    "            \"\"\"\n",
    "            \n",
    "            text = text.split()\n",
    "            new_text = [word for word in text if word not in stop_words]\n",
    "            new_text = ' '.join(new_text)\n",
    "            \n",
    "            return new_text\n",
    "        \n",
    "        def _update_word_count(self):\n",
    "            \"\"\"Update the count of all the words, the text is cleared and stop words are removed as well \n",
    "            \n",
    "            \"\"\"\n",
    "              \n",
    "            for subject in self.training_data :\n",
    "                for word in self._remove_stop_words(self._clear_text(subject), self._stop_words).split():\n",
    "                    if word in self.bag_of_words:\n",
    "                        self.bag_of_words[word].count += 1 \n",
    "                    else:\n",
    "                        self.bag_of_words[word] = self.CountProbability (1, 0) \n",
    "                        \n",
    "        def _update_word_probability(self):\n",
    "            \"\"\"Update the probability of each word within the entire set\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            for word in self.bag_of_words :\n",
    "                stats = self.bag_of_words[word]\n",
    "                \n",
    "                stats.probability = stats.count + 1 / len(self.training_data) + 2 # Laplace smoothing\n",
    "                                 \n",
    "        class CountProbability:\n",
    "\n",
    "            def __init__(self, count, probability):\n",
    "                self.count = count\n",
    "                self.probability = probability\n",
    "                \n",
    "            def __repr__(self):\n",
    "                return f\"{self.count} {self.probability}\"\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T05:22:35.501855Z",
     "start_time": "2024-10-20T05:22:35.473253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spamFilter = NaiveBayesSpamFilter([\"us\", \"your\", \"our\", \"the\", \"of\"], previous_ham, previous_spam)\n",
    "\n",
    "spamFilter.build_training_set_dictionary()\n",
    "spamFilter.predict(new_emails)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global bag of words for ham -----------------\n",
      "dict_keys(['activity', 'report', 'benefits', 'physical', 'importance', 'vows'])\n",
      "dict_values([2 4.166666666666666, 1 3.166666666666667, 1 3.166666666666667, 1 3.166666666666667, 1 3.166666666666667, 1 3.166666666666667])\n",
      "\n",
      "Global bag of words for spam ---------------\n",
      "dict_keys(['send', 'password', 'review', 'website', 'account'])\n",
      "dict_values([3 5.125, 2 4.125, 1 3.125, 1 3.125, 1 3.125])\n",
      "\n",
      "spam: ['renew your password', 'renew your vows']\n",
      "spam P: 0.8586113000442763 ham P: -0.8469390049147263\n",
      "spam\n",
      "spam P: -0.5594592322254455 ham P: 0.3064050953786035\n",
      "ham\n",
      "ham: ['benefits of our account', 'the importance of physical activity']\n",
      "spam P: 0.5806244528326898 ham P: 0.3064050953786035\n",
      "spam\n",
      "spam P: -0.5594592322254455 ham P: 2.8878843664567055\n",
      "ham\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T05:23:18.300070Z",
     "start_time": "2024-10-20T05:23:18.284071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# spam of text never seen \n",
    "new_emails = {'spam':['you have never seen me']}\n",
    "spamFilter.predict(new_emails)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam: ['you have never seen me']\n",
      "spam P: -0.5594592322254455 ham P: -0.8469390049147263\n",
      "spam\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:37:09.389813Z",
     "start_time": "2024-10-20T15:37:09.367531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "\n",
    "     P_S = 4 / 7       -> 0.57 - >  log(0.57) -> - 0.56\n",
    "     P_H = 1 - 0.57    -> 0.43 - >  log(0.43) -> - 0.84\n",
    "     \n",
    "     The probability of  P(x | S) or P (s | H) is zero since we have empty objects, as the words are not present in the training set:\n",
    "     \n",
    "     so it is LOG(P_S) > LOG(P_H) for words that are not present in the training set \n",
    "     \n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n     P_S = 4 / 7       -> 0.57 - >  log(0.57) -> - 0.56\\n     P_H = 1 - 0.57    -> 0.43 - >  log(0.43) -> - 0.84\\n     \\n     The probability of  P(x | S) or P (s | H) is zero since we have empty objects, as the words are not present in the training set:\\n     \\n     so it is LOG(P_S) > LOG(P_H) for words that are not present in the training set \\n     \\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T05:21:18.096511Z",
     "start_time": "2024-10-20T05:21:18.069892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# spam of text never seen \n",
    "new_emails = {'ham':['activity report benefits physical importance vows']}\n",
    "spamFilter.predict(new_emails)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham: ['activity report benefits physical importance vows']\n",
      "spam P: -0.5594592322254455 ham P: 6.347916667336695\n",
      "ham\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T05:21:30.769389Z",
     "start_time": "2024-10-20T05:21:30.747394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# spam / ham  50 50 :) \n",
    "new_emails = {'spam':['activity report review website']}\n",
    "spamFilter.predict(new_emails)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam: ['activity report review website']\n",
      "spam P: 1.720708137890825 ham P: 1.7345402661633758\n",
      "ham\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write you reflection in below cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I implemented a custom log method , since we are not allowed to use any external libraries.\n",
    "* Finished the code by getting inspiration from external articles, where data is sanitised and then stop words are removed. I put together a simple stop word list and the clean-up, lowers the casing of all the characters. There are more complex operation one can perform on the data before submitting it to the model, but for the POC it will do .\n",
    "* I'm not removing duplicated words from the subject \n",
    "* Laplace smoothing is used to calculate the probability and then a custom log function is applied so that we get the sum of all the probabilities , instead of having to multiple them.\n",
    "* I went for a class structure to make it easy to read the code \n",
    "* I like how simple it makes the code the log of P_S and P_H and log of the sum of probabilities can be used to classify the subjects , without having to worry about the 0.5 threshold .\n",
    "* One negative aspect of the algorithm, it assumes words are independent and the words in ham and spam bags of words are unique, there are no overlaps. But in reality sometimes a given word can be a ham or spam based on the context.\n",
    "* Also, the output is based on the quality of the training data, it is a given for all the model , but in this case it dictates what is a ham or spam when the input is has never been seen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
